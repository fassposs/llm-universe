{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ç¬¬å››ç«  æ„å»ºRAGåº”ç”¨\n",
    "\n",
    "## 4.1 å°†LLM æ¥å…¥ LangChain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LangChain ä¸ºåŸºäº LLM å¼€å‘è‡ªå®šä¹‰åº”ç”¨æä¾›äº†é«˜æ•ˆçš„å¼€å‘æ¡†æ¶ï¼Œä¾¿äºå¼€å‘è€…è¿…é€Ÿåœ°æ¿€å‘ LLM çš„å¼ºå¤§èƒ½åŠ›ï¼Œæ­å»º LLM åº”ç”¨ã€‚LangChain ä¹ŸåŒæ ·æ”¯æŒå¤šç§å¤§æ¨¡å‹ï¼Œå†…ç½®äº† OpenAIã€LLAMA ç­‰å¤§æ¨¡å‹çš„è°ƒç”¨æ¥å£ã€‚ä½†æ˜¯ï¼ŒLangChain å¹¶æ²¡æœ‰å†…ç½®æ‰€æœ‰å¤§æ¨¡å‹ï¼Œå®ƒé€šè¿‡å…è®¸ç”¨æˆ·è‡ªå®šä¹‰ LLM ç±»å‹ï¼Œæ¥æä¾›å¼ºå¤§çš„å¯æ‰©å±•æ€§ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.1 åŸºäº LangChain è°ƒç”¨ ChatGPT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LangChain æä¾›äº†å¯¹äºå¤šç§å¤§æ¨¡å‹çš„å°è£…ï¼ŒåŸºäº LangChain çš„æ¥å£å¯ä»¥ä¾¿æ·åœ°è°ƒç”¨ ChatGPT å¹¶å°†å…¶é›†åˆåœ¨ä»¥ LangChain ä¸ºåŸºç¡€æ¡†æ¶æ­å»ºçš„ä¸ªäººåº”ç”¨ä¸­ã€‚æˆ‘ä»¬åœ¨æ­¤ç®€è¿°å¦‚ä½•ä½¿ç”¨ LangChain æ¥å£æ¥è°ƒç”¨ ChatGPTã€‚\n",
    "\n",
    "æ³¨æ„ï¼ŒåŸºäº LangChain æ¥å£è°ƒç”¨ ChatGPT åŒæ ·éœ€è¦é…ç½®ä½ çš„ä¸ªäººå¯†é’¥ï¼Œé…ç½®æ–¹æ³•åŒä¸Šã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ä» `langchain.chat_models` å¯¼å…¥ `OpenAI` çš„å¯¹è¯æ¨¡å‹ `ChatOpenAI` ã€‚ é™¤å»OpenAIä»¥å¤–ï¼Œ`langchain.chat_models` è¿˜é›†æˆäº†å…¶ä»–å¯¹è¯æ¨¡å‹ï¼Œæ›´å¤šç»†èŠ‚å¯ä»¥æŸ¥çœ‹[Langchainå®˜æ–¹æ–‡æ¡£](https://api.python.langchain.com/en/latest/langchain_api_reference.html#module-langchain.chat_models)ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "# è¯»å–æœ¬åœ°/é¡¹ç›®çš„ç¯å¢ƒå˜é‡ã€‚\n",
    "\n",
    "# find_dotenv()å¯»æ‰¾å¹¶å®šä½.envæ–‡ä»¶çš„è·¯å¾„\n",
    "# load_dotenv()è¯»å–è¯¥.envæ–‡ä»¶ï¼Œå¹¶å°†å…¶ä¸­çš„ç¯å¢ƒå˜é‡åŠ è½½åˆ°å½“å‰çš„è¿è¡Œç¯å¢ƒä¸­  \n",
    "# å¦‚æœä½ è®¾ç½®çš„æ˜¯å…¨å±€çš„ç¯å¢ƒå˜é‡ï¼Œè¿™è¡Œä»£ç åˆ™æ²¡æœ‰ä»»ä½•ä½œç”¨ã€‚\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "# è·å–ç¯å¢ƒå˜é‡ OPENAI_API_KEY\n",
    "openai_api_key = os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æ²¡æœ‰å®‰è£… langchain-openai çš„è¯ï¼Œè¯·å…ˆè¿è¡Œä¸‹é¢è¿›è¡Œä»£ç ï¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æ¥ä¸‹æ¥ä½ éœ€è¦å®ä¾‹åŒ–ä¸€ä¸ª ChatOpenAI ç±»ï¼Œå¯ä»¥åœ¨å®ä¾‹åŒ–æ—¶ä¼ å…¥è¶…å‚æ•°æ¥æ§åˆ¶å›ç­”ï¼Œä¾‹å¦‚ `temperature` å‚æ•°ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# è¿™é‡Œæˆ‘ä»¬å°†å‚æ•°temperatureè®¾ç½®ä¸º0.0ï¼Œä»è€Œå‡å°‘ç”Ÿæˆç­”æ¡ˆçš„éšæœºæ€§ã€‚\n",
    "# å¦‚æœä½ æƒ³è¦æ¯æ¬¡å¾—åˆ°ä¸ä¸€æ ·çš„æœ‰æ–°æ„çš„ç­”æ¡ˆï¼Œå¯ä»¥å°è¯•è°ƒæ•´è¯¥å‚æ•°ã€‚\n",
    "llm = ChatOpenAI(temperature=0.0)\n",
    "llm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ä¸Šé¢çš„ cell å‡è®¾ä½ çš„ OpenAI API å¯†é’¥æ˜¯åœ¨ç¯å¢ƒå˜é‡ä¸­è®¾ç½®çš„ï¼Œå¦‚æœæ‚¨å¸Œæœ›æ‰‹åŠ¨æŒ‡å®šAPIå¯†é’¥ï¼Œè¯·ä½¿ç”¨ä»¥ä¸‹ä»£ç ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm = ChatOpenAI(temperature=0, openai_api_key=\"YOUR_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "å¯ä»¥çœ‹åˆ°ï¼Œé»˜è®¤è°ƒç”¨çš„æ˜¯ ChatGPT-3.5 æ¨¡å‹ã€‚å¦å¤–ï¼Œå‡ ç§å¸¸ç”¨çš„è¶…å‚æ•°è®¾ç½®åŒ…æ‹¬ï¼š\n",
    "\n",
    "    Â· model_nameï¼šæ‰€è¦ä½¿ç”¨çš„æ¨¡å‹ï¼Œé»˜è®¤ä¸º â€˜gpt-3.5-turboâ€™ï¼Œå‚æ•°è®¾ç½®ä¸ OpenAI åŸç”Ÿæ¥å£å‚æ•°è®¾ç½®ä¸€è‡´ã€‚\n",
    "\n",
    "    Â· temperatureï¼šæ¸©åº¦ç³»æ•°ï¼Œå–å€¼åŒåŸç”Ÿæ¥å£ã€‚\n",
    "\n",
    "    Â· openai_api_keyï¼šOpenAI API keyï¼Œå¦‚æœä¸ä½¿ç”¨ç¯å¢ƒå˜é‡è®¾ç½® API Keyï¼Œä¹Ÿå¯ä»¥åœ¨å®ä¾‹åŒ–æ—¶è®¾ç½®ã€‚\n",
    "\n",
    "    Â· openai_proxyï¼šè®¾ç½®ä»£ç†ï¼Œå¦‚æœä¸ä½¿ç”¨ç¯å¢ƒå˜é‡è®¾ç½®ä»£ç†ï¼Œä¹Ÿå¯ä»¥åœ¨å®ä¾‹åŒ–æ—¶è®¾ç½®ã€‚\n",
    "\n",
    "    Â· streamingï¼šæ˜¯å¦ä½¿ç”¨æµå¼ä¼ è¾“ï¼Œå³é€å­—è¾“å‡ºæ¨¡å‹å›ç­”ï¼Œé»˜è®¤ä¸º Falseï¼Œæ­¤å¤„ä¸èµ˜è¿°ã€‚\n",
    "\n",
    "    Â· max_tokensï¼šæ¨¡å‹è¾“å‡ºçš„æœ€å¤§ token æ•°ï¼Œæ„ä¹‰åŠå–å€¼åŒä¸Šã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "å½“æˆ‘ä»¬åˆå§‹åŒ–äº†ä½ é€‰æ‹©çš„`LLM`åï¼Œæˆ‘ä»¬å°±å¯ä»¥å°è¯•ä½¿ç”¨å®ƒï¼è®©æˆ‘ä»¬é—®ä¸€ä¸‹â€œè¯·ä½ è‡ªæˆ‘ä»‹ç»ä¸€ä¸‹è‡ªå·±ï¼â€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = llm.invoke(\"è¯·ä½ è‡ªæˆ‘ä»‹ç»ä¸€ä¸‹è‡ªå·±ï¼\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "åœ¨æˆ‘ä»¬å¼€å‘å¤§æ¨¡å‹åº”ç”¨æ—¶ï¼Œå¤§å¤šæ•°æƒ…å†µä¸‹ä¸ä¼šç›´æ¥å°†ç”¨æˆ·çš„è¾“å…¥ç›´æ¥ä¼ é€’ç»™ LLMã€‚é€šå¸¸ï¼Œä»–ä»¬ä¼šå°†ç”¨æˆ·è¾“å…¥æ·»åŠ åˆ°ä¸€ä¸ªè¾ƒå¤§çš„æ–‡æœ¬ä¸­ï¼Œç§°ä¸º`æç¤ºæ¨¡æ¿`ï¼Œè¯¥æ–‡æœ¬æä¾›æœ‰å…³å½“å‰ç‰¹å®šä»»åŠ¡çš„é™„åŠ ä¸Šä¸‹æ–‡ã€‚\n",
    "PromptTemplates æ­£æ˜¯å¸®åŠ©è§£å†³è¿™ä¸ªé—®é¢˜ï¼å®ƒä»¬æ†ç»‘äº†ä»ç”¨æˆ·è¾“å…¥åˆ°å®Œå…¨æ ¼å¼åŒ–çš„æç¤ºçš„æ‰€æœ‰é€»è¾‘ã€‚è¿™å¯ä»¥éå¸¸ç®€å•åœ°å¼€å§‹ - ä¾‹å¦‚ï¼Œç”Ÿæˆä¸Šè¿°å­—ç¬¦ä¸²çš„æç¤ºå°±æ˜¯ï¼š\n",
    "\n",
    "\n",
    "æˆ‘ä»¬éœ€è¦å…ˆæ„é€ ä¸€ä¸ªä¸ªæ€§åŒ– Templateï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# è¿™é‡Œæˆ‘ä»¬è¦æ±‚æ¨¡å‹å¯¹ç»™å®šæ–‡æœ¬è¿›è¡Œä¸­æ–‡ç¿»è¯‘\n",
    "prompt = \"\"\"è¯·ä½ å°†ç”±ä¸‰ä¸ªåå¼•å·åˆ†å‰²çš„æ–‡æœ¬ç¿»è¯‘æˆè‹±æ–‡ï¼\\\n",
    "text: ```{text}```\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æ¥ä¸‹æ¥è®©æˆ‘ä»¬çœ‹ä¸€ä¸‹æ„é€ å¥½çš„å®Œæ•´çš„æç¤ºæ¨¡ç‰ˆï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"æˆ‘å¸¦ç€æ¯”èº«ä½“é‡çš„è¡Œæï¼Œ\\\n",
    "æ¸¸å…¥å°¼ç½—æ²³åº•ï¼Œ\\\n",
    "ç»è¿‡å‡ é“é—ªç”µ çœ‹åˆ°ä¸€å †å…‰åœˆï¼Œ\\\n",
    "ä¸ç¡®å®šæ˜¯ä¸æ˜¯è¿™é‡Œã€‚\\\n",
    "\"\n",
    "prompt.format(text=text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æˆ‘ä»¬çŸ¥é“èŠå¤©æ¨¡å‹çš„æ¥å£æ˜¯åŸºäºæ¶ˆæ¯ï¼ˆmessageï¼‰ï¼Œè€Œä¸æ˜¯åŸå§‹çš„æ–‡æœ¬ã€‚PromptTemplates ä¹Ÿå¯ä»¥ç”¨äºäº§ç”Ÿæ¶ˆæ¯åˆ—è¡¨ï¼Œåœ¨è¿™ç§æ ·ä¾‹ä¸­ï¼Œ`prompt`ä¸ä»…åŒ…å«äº†è¾“å…¥å†…å®¹ä¿¡æ¯ï¼Œä¹ŸåŒ…å«äº†æ¯æ¡`message`çš„ä¿¡æ¯(è§’è‰²ã€åœ¨åˆ—è¡¨ä¸­çš„ä½ç½®ç­‰)ã€‚é€šå¸¸æƒ…å†µä¸‹ï¼Œä¸€ä¸ª `ChatPromptTemplate` æ˜¯ä¸€ä¸ª `ChatMessageTemplate` çš„åˆ—è¡¨ã€‚æ¯ä¸ª `ChatMessageTemplate` åŒ…å«æ ¼å¼åŒ–è¯¥èŠå¤©æ¶ˆæ¯çš„è¯´æ˜ï¼ˆå…¶è§’è‰²ä»¥åŠå†…å®¹ï¼‰ã€‚\n",
    "\n",
    "è®©æˆ‘ä»¬ä¸€èµ·çœ‹ä¸€ä¸ªç¤ºä¾‹ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "template = \"ä½ æ˜¯ä¸€ä¸ªç¿»è¯‘åŠ©æ‰‹ï¼Œå¯ä»¥å¸®åŠ©æˆ‘å°† {input_language} ç¿»è¯‘æˆ {output_language}.\"\n",
    "human_template = \"{text}\"\n",
    "\n",
    "chat_prompt = ChatPromptTemplate([\n",
    "    (\"system\", template),\n",
    "    (\"human\", human_template),\n",
    "])\n",
    "\n",
    "text = \"æˆ‘å¸¦ç€æ¯”èº«ä½“é‡çš„è¡Œæï¼Œ\\\n",
    "æ¸¸å…¥å°¼ç½—æ²³åº•ï¼Œ\\\n",
    "ç»è¿‡å‡ é“é—ªç”µ çœ‹åˆ°ä¸€å †å…‰åœˆï¼Œ\\\n",
    "ä¸ç¡®å®šæ˜¯ä¸æ˜¯è¿™é‡Œã€‚\\\n",
    "\"\n",
    "messages  = chat_prompt.invoke({\"input_language\": \"ä¸­æ–‡\", \"output_language\": \"è‹±æ–‡\", \"text\": text})\n",
    "messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æ¥ä¸‹æ¥è®©æˆ‘ä»¬è°ƒç”¨å®šä¹‰å¥½çš„`llm`å’Œ`messages`æ¥è¾“å‡ºå›ç­”ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output  = llm.invoke(messages)\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OutputParsers å°†è¯­è¨€æ¨¡å‹çš„åŸå§‹è¾“å‡ºè½¬æ¢ä¸ºå¯ä»¥åœ¨ä¸‹æ¸¸ä½¿ç”¨çš„æ ¼å¼ã€‚ OutputParsers æœ‰å‡ ç§ä¸»è¦ç±»å‹ï¼ŒåŒ…æ‹¬ï¼š\n",
    "- å°† LLM æ–‡æœ¬è½¬æ¢ä¸ºç»“æ„åŒ–ä¿¡æ¯ï¼ˆä¾‹å¦‚ JSONï¼‰ \n",
    "- å°† ChatMessage è½¬æ¢ä¸ºå­—ç¬¦ä¸² \n",
    "- å°†é™¤æ¶ˆæ¯ä¹‹å¤–çš„è°ƒç”¨è¿”å›çš„é¢å¤–ä¿¡æ¯ï¼ˆå¦‚ OpenAI å‡½æ•°è°ƒç”¨ï¼‰è½¬æ¢ä¸ºå­—ç¬¦ä¸²\n",
    "\n",
    "æœ€åï¼Œæˆ‘ä»¬å°†æ¨¡å‹è¾“å‡ºä¼ é€’ç»™ `output_parser`ï¼Œå®ƒæ˜¯ä¸€ä¸ª `BaseOutputParser`ï¼Œè¿™æ„å‘³ç€å®ƒæ¥å—**å­—ç¬¦ä¸²æˆ– BaseMessage ä½œä¸ºè¾“å…¥**ã€‚ StrOutputParser ç‰¹åˆ«ç®€å•åœ°å°†ä»»ä½•è¾“å…¥è½¬æ¢ä¸ºå­—ç¬¦ä¸²ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "output_parser = StrOutputParser()\n",
    "output_parser.invoke(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ä»ä¸Šé¢ç»“æœå¯ä»¥çœ‹åˆ°ï¼Œæˆ‘ä»¬é€šè¿‡è¾“å‡ºè§£æå™¨æˆåŠŸå°† `ChatMessage` ç±»å‹çš„è¾“å‡ºè§£æä¸ºäº†`å­—ç¬¦ä¸²`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æˆ‘ä»¬ç°åœ¨å¯ä»¥å°†æ‰€æœ‰è¿™äº›ç»„åˆæˆä¸€æ¡é“¾ã€‚è¯¥é“¾å°†è·å–è¾“å…¥å˜é‡ï¼Œå°†è¿™äº›å˜é‡ä¼ é€’ç»™æç¤ºæ¨¡æ¿ä»¥åˆ›å»ºæç¤ºï¼Œå°†æç¤ºä¼ é€’ç»™è¯­è¨€æ¨¡å‹ï¼Œç„¶åé€šè¿‡ï¼ˆå¯é€‰ï¼‰è¾“å‡ºè§£æå™¨ä¼ é€’è¾“å‡ºã€‚æ¥ä¸‹æ¥æˆ‘ä»¬å°†ä½¿ç”¨LCELè¿™ç§è¯­æ³•å»å¿«é€Ÿå®ç°ä¸€æ¡é“¾ï¼ˆchainï¼‰ã€‚è®©æˆ‘ä»¬çœ‹çœ‹å®ƒçš„å®é™…æ•ˆæœï¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = chat_prompt | llm | output_parser\n",
    "chain.invoke({\"input_language\":\"ä¸­æ–‡\", \"output_language\":\"è‹±æ–‡\",\"text\": text})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "å†æµ‹è¯•ä¸€ä¸ªæ ·ä¾‹ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'I carried luggage heavier than my body and dived into the bottom of the Nile River. After passing through several flashes of lightning, I saw a pile of halos, not sure if this is the place.'\n",
    "chain.invoke({\"input_language\": \"è‹±æ–‡\", \"output_language\": \"ä¸­æ–‡\",\"text\": text})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ä»€ä¹ˆæ˜¯ LCEL ï¼Ÿ \n",
    "LCELï¼ˆLangChain Expression Languageï¼ŒLangchainçš„è¡¨è¾¾å¼è¯­è¨€ï¼‰ï¼ŒLCELæ˜¯ä¸€ç§æ–°çš„è¯­æ³•ï¼Œæ˜¯LangChainå·¥å…·åŒ…çš„é‡è¦è¡¥å……ï¼Œä»–æœ‰è®¸å¤šä¼˜ç‚¹ï¼Œä½¿å¾—æˆ‘ä»¬å¤„ç†LangChainå’Œä»£ç†æ›´åŠ ç®€å•æ–¹ä¾¿ã€‚\n",
    "\n",
    "- LCELæä¾›äº†å¼‚æ­¥ã€æ‰¹å¤„ç†å’Œæµå¤„ç†æ”¯æŒï¼Œä½¿ä»£ç å¯ä»¥å¿«é€Ÿåœ¨ä¸åŒæœåŠ¡å™¨ä¸­ç§»æ¤ã€‚\n",
    "- LCELæ‹¥æœ‰åå¤‡æªæ–½ï¼Œè§£å†³LLMæ ¼å¼è¾“å‡ºçš„é—®é¢˜ã€‚\n",
    "- LCELå¢åŠ äº†LLMçš„å¹¶è¡Œæ€§ï¼Œæé«˜äº†æ•ˆç‡ã€‚\n",
    "- LCELå†…ç½®äº†æ—¥å¿—è®°å½•ï¼Œå³ä½¿ä»£ç†å˜å¾—å¤æ‚ï¼Œæœ‰åŠ©äºç†è§£å¤æ‚é“¾æ¡å’Œä»£ç†çš„è¿è¡Œæƒ…å†µã€‚\n",
    "\n",
    "ç”¨æ³•ç¤ºä¾‹ï¼š\n",
    "\n",
    "`chain = prompt | model | output_parser`\n",
    "\n",
    "ä¸Šé¢ä»£ç ä¸­æˆ‘ä»¬ä½¿ç”¨ LCEL å°†ä¸åŒçš„ç»„ä»¶æ‹¼å‡‘æˆä¸€ä¸ªé“¾ï¼Œåœ¨æ­¤é“¾ä¸­ï¼Œç”¨æˆ·è¾“å…¥ä¼ é€’åˆ°æç¤ºæ¨¡æ¿ï¼Œç„¶åæç¤ºæ¨¡æ¿è¾“å‡ºä¼ é€’åˆ°æ¨¡å‹ï¼Œç„¶åæ¨¡å‹è¾“å‡ºä¼ é€’åˆ°è¾“å‡ºè§£æå™¨ã€‚| çš„ç¬¦å·ç±»ä¼¼äº Unix ç®¡é“è¿ç®—ç¬¦ï¼Œå®ƒå°†ä¸åŒçš„ç»„ä»¶é“¾æ¥åœ¨ä¸€èµ·ï¼Œå°†ä¸€ä¸ªç»„ä»¶çš„è¾“å‡ºä½œä¸ºä¸‹ä¸€ä¸ªç»„ä»¶çš„è¾“å…¥ã€‚\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.2 ä½¿ç”¨ LangChain è°ƒç”¨ç™¾åº¦æ–‡å¿ƒä¸€è¨€"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æˆ‘ä»¬åŒæ ·å¯ä»¥é€šè¿‡ LangChain æ¡†æ¶æ¥è°ƒç”¨ç™¾åº¦æ–‡å¿ƒå¤§æ¨¡å‹ï¼Œä»¥å°†æ–‡å¿ƒæ¨¡å‹æ¥å…¥åˆ°æˆ‘ä»¬çš„åº”ç”¨æ¡†æ¶ä¸­ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "import os\n",
    "\n",
    "# è¯»å–æœ¬åœ°/é¡¹ç›®çš„ç¯å¢ƒå˜é‡ã€‚\n",
    "\n",
    "# find_dotenv()å¯»æ‰¾å¹¶å®šä½.envæ–‡ä»¶çš„è·¯å¾„\n",
    "# load_dotenv()è¯»å–è¯¥.envæ–‡ä»¶ï¼Œå¹¶å°†å…¶ä¸­çš„ç¯å¢ƒå˜é‡åŠ è½½åˆ°å½“å‰çš„è¿è¡Œç¯å¢ƒä¸­\n",
    "# å¦‚æœä½ è®¾ç½®çš„æ˜¯å…¨å±€çš„ç¯å¢ƒå˜é‡ï¼Œè¿™è¡Œä»£ç åˆ™æ²¡æœ‰ä»»ä½•ä½œç”¨ã€‚\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "# è·å–ç¯å¢ƒå˜é‡ API_KEY\n",
    "QIANFAN_AK = os.environ[\"QIANFAN_AK\"]\n",
    "QIANFAN_SK = os.environ[\"QIANFAN_SK\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms.baidu_qianfan_endpoint import QianfanLLMEndpoint\n",
    "\n",
    "llm = QianfanLLMEndpoint(streaming=True)\n",
    "res = llm(\"ä½ å¥½ï¼Œè¯·ä½ è‡ªæˆ‘ä»‹ç»ä¸€ä¸‹ï¼\")\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.3 è®¯é£æ˜Ÿç«"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æˆ‘ä»¬åŒæ ·å¯ä»¥é€šè¿‡ LangChain æ¡†æ¶æ¥è°ƒç”¨è®¯é£æ˜Ÿç«å¤§æ¨¡å‹ï¼Œæ›´å¤šä¿¡æ¯å‚è€ƒ[SparkLLM](https://python.langchain.com/docs/integrations/llms/sparkllm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æˆ‘ä»¬å¸Œæœ›åƒè°ƒç”¨ ChatGPT é‚£æ ·ç›´æ¥å°†ç§˜é’¥å­˜å‚¨åœ¨ .env æ–‡ä»¶ä¸­ï¼Œå¹¶å°†å…¶åŠ è½½åˆ°ç¯å¢ƒå˜é‡ï¼Œä»è€Œéšè—ç§˜é’¥çš„å…·ä½“ç»†èŠ‚ï¼Œä¿è¯å®‰å…¨æ€§ã€‚å› æ­¤ï¼Œæˆ‘ä»¬éœ€è¦åœ¨ .env æ–‡ä»¶ä¸­é…ç½®`IFLYTEK_SPARK_APP_ID`ã€ `IFLYTEK_SPARK_API_KEY` å’Œ `IFLYTEK_SPARK_API_SECRET`ï¼Œå¹¶ä½¿ç”¨ä»¥ä¸‹ä»£ç åŠ è½½ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import find_dotenv, load_dotenv\n",
    "import os\n",
    "\n",
    "# è¯»å–æœ¬åœ°/é¡¹ç›®çš„ç¯å¢ƒå˜é‡ã€‚\n",
    "\n",
    "# find_dotenv()å¯»æ‰¾å¹¶å®šä½.envæ–‡ä»¶çš„è·¯å¾„\n",
    "# load_dotenv()è¯»å–è¯¥.envæ–‡ä»¶ï¼Œå¹¶å°†å…¶ä¸­çš„ç¯å¢ƒå˜é‡åŠ è½½åˆ°å½“å‰çš„è¿è¡Œç¯å¢ƒä¸­\n",
    "# å¦‚æœä½ è®¾ç½®çš„æ˜¯å…¨å±€çš„ç¯å¢ƒå˜é‡ï¼Œè¿™è¡Œä»£ç åˆ™æ²¡æœ‰ä»»ä½•ä½œç”¨ã€‚\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "# è·å–ç¯å¢ƒå˜é‡ API_KEY\n",
    "IFLYTEK_SPARK_APP_ID = os.environ[\"IFLYTEK_SPARK_APP_ID\"]\n",
    "IFLYTEK_SPARK_API_KEY = os.environ[\"IFLYTEK_SPARK_API_KEY\"]\n",
    "IFLYTEK_SPARK_API_SECRET = os.environ[\"IFLYTEK_SPARK_API_SECRET\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "å¦å¤–æ˜Ÿç«å„æ¨¡å‹å¯¹åº”çš„`spark_api_url`ä¸`spark_llm_domain`å‡ä¸ç›¸åŒï¼Œå¯ä»¥å‚è€ƒ[æ¥å£è¯´æ˜](https://www.xfyun.cn/doc/spark/Web.html#_1-%E6%8E%A5%E5%8F%A3%E8%AF%B4%E6%98%8E)é€‰æ‹©è°ƒç”¨ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms.sparkllm import SparkLLM\n",
    "\n",
    "# Load the model\n",
    "llm = SparkLLM(\n",
    "    model='Spark4.0 Ultra',\n",
    "    app_id=IFLYTEK_SPARK_APP_ID,\n",
    "    api_key=IFLYTEK_SPARK_API_KEY,\n",
    "    api_secret=IFLYTEK_SPARK_API_SECRET,\n",
    "    spark_api_url=\"wss://spark-api.xf-yun.com/v4.0/chat\",\n",
    "    spark_llm_domain=\"4.0Ultra\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = llm.invoke(\"ä½ å¥½ï¼Œè¯·ä½ è‡ªæˆ‘ä»‹ç»ä¸€ä¸‹ï¼\")\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ä»è€Œæˆ‘ä»¬å¯ä»¥å°†æ˜Ÿç«å¤§æ¨¡å‹åŠ å…¥åˆ° LangChain æ¶æ„ä¸­ï¼Œå®ç°åœ¨åº”ç”¨ä¸­å¯¹æ–‡å¿ƒå¤§æ¨¡å‹çš„è°ƒç”¨ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.4 ä½¿ç”¨ LangChain è°ƒç”¨æ™ºè°± GLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æˆ‘ä»¬åŒæ ·å¯ä»¥é€šè¿‡ LangChain æ¡†æ¶æ¥è°ƒç”¨æ™ºè°± AI å¤§æ¨¡å‹ï¼Œä»¥å°†å…¶æ¥å…¥åˆ°æˆ‘ä»¬çš„åº”ç”¨æ¡†æ¶ä¸­ã€‚ç”±äº langchain ä¸­æä¾›çš„[ChatGLM](https://python.langchain.com/docs/integrations/llms/chatglm)å·²ä¸å¯ç”¨ï¼Œå› æ­¤æˆ‘ä»¬éœ€è¦è‡ªå®šä¹‰ä¸€ä¸ªLLMã€‚\n",
    "\n",
    "å¦‚æœä½ ä½¿ç”¨çš„æ˜¯æ™ºè°± GLM APIï¼Œä½ éœ€è¦å°†æˆ‘ä»¬å°è£…çš„ä»£ç [zhipuai_llm.py](./zhipuai_llm.py)ä¸‹è½½åˆ°æœ¬ Notebook çš„åŒçº§ç›®å½•ä¸‹ï¼Œæ‰å¯ä»¥è¿è¡Œä¸‹åˆ—ä»£ç æ¥åœ¨ LangChain ä¸­ä½¿ç”¨ GLMã€‚\n",
    "\n",
    "æ ¹æ®æ™ºè°±å®˜æ–¹å®£å¸ƒä»¥ä¸‹æ¨¡å‹å³å°†å¼ƒç”¨ï¼Œåœ¨è¿™äº›æ¨¡å‹å¼ƒç”¨åï¼Œä¼šå°†å®ƒä»¬è‡ªåŠ¨è·¯ç”±è‡³æ–°çš„æ¨¡å‹ã€‚è¯·ç”¨æˆ·æ³¨æ„åœ¨å¼ƒç”¨æ—¥æœŸä¹‹å‰ï¼Œå°†æ‚¨çš„æ¨¡å‹ç¼–ç æ›´æ–°ä¸ºæœ€æ–°ç‰ˆæœ¬ï¼Œä»¥ç¡®ä¿æœåŠ¡çš„é¡ºç•…è¿‡æ¸¡ï¼Œæ›´å¤šæ¨¡å‹ç›¸å…³ä¿¡æ¯è¯·è®¿é—®[model](https://open.bigmodel.cn/dev/howuse/model)\n",
    "\n",
    "| æ¨¡å‹ç¼–ç  |å¼ƒç”¨æ—¥æœŸ|æŒ‡å‘æ¨¡å‹|\n",
    "| ---- | ---- | ---- |\n",
    "|chatglm_pro|2024 å¹´ 12 æœˆ 31 æ—¥|glm-4|\n",
    "|chatglm_std|2024 å¹´ 12 æœˆ 31 æ—¥|glm-3-turbo|\n",
    "|chatglm_lite|2024 å¹´ 12 æœˆ 31 æ—¥|glm-3-turbo|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zhipuai_llm import ZhipuaiLLM\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "import os\n",
    "\n",
    "# è¯»å–æœ¬åœ°/é¡¹ç›®çš„ç¯å¢ƒå˜é‡ã€‚\n",
    "\n",
    "# find_dotenv()å¯»æ‰¾å¹¶å®šä½.envæ–‡ä»¶çš„è·¯å¾„\n",
    "# load_dotenv()è¯»å–è¯¥.envæ–‡ä»¶ï¼Œå¹¶å°†å…¶ä¸­çš„ç¯å¢ƒå˜é‡åŠ è½½åˆ°å½“å‰çš„è¿è¡Œç¯å¢ƒä¸­\n",
    "# å¦‚æœä½ è®¾ç½®çš„æ˜¯å…¨å±€çš„ç¯å¢ƒå˜é‡ï¼Œè¿™è¡Œä»£ç åˆ™æ²¡æœ‰ä»»ä½•ä½œç”¨ã€‚\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "# è·å–ç¯å¢ƒå˜é‡ API_KEY\n",
    "api_key = os.environ[\"ZHIPUAI_API_KEY\"] #å¡«å†™æ§åˆ¶å°ä¸­è·å–çš„ APIKey ä¿¡æ¯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zhipuai_model = ZhipuaiLLM(model_name=\"glm-4-plus\", temperature=0.1, api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zhipuai_model.invoke(\"ä½ å¥½ï¼Œè¯·ä½ è‡ªæˆ‘ä»‹ç»ä¸€ä¸‹ï¼\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 æ„å»ºæ£€ç´¢é—®ç­”é“¾"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "åœ¨ `C3 æ­å»ºæ•°æ®åº“` ç« èŠ‚ï¼Œæˆ‘ä»¬å·²ç»ä»‹ç»äº†å¦‚ä½•æ ¹æ®è‡ªå·±çš„æœ¬åœ°çŸ¥è¯†æ–‡æ¡£ï¼Œæ­å»ºä¸€ä¸ªå‘é‡çŸ¥è¯†åº“ã€‚ åœ¨æ¥ä¸‹æ¥çš„å†…å®¹é‡Œï¼Œæˆ‘ä»¬å°†ä½¿ç”¨æ­å»ºå¥½çš„å‘é‡æ•°æ®åº“ï¼Œå¯¹ query æŸ¥è¯¢é—®é¢˜è¿›è¡Œå¬å›ï¼Œå¹¶å°†å¬å›ç»“æœå’Œ query ç»“åˆèµ·æ¥æ„å»º promptï¼Œè¾“å…¥åˆ°å¤§æ¨¡å‹ä¸­è¿›è¡Œé—®ç­”ã€‚   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.1 åŠ è½½å‘é‡æ•°æ®åº“\n",
    "\n",
    "é¦–å…ˆï¼Œæˆ‘ä»¬åŠ è½½åœ¨å‰ä¸€ç« å·²ç»æ„å»ºçš„å‘é‡æ•°æ®åº“ã€‚æ³¨æ„ï¼Œæ­¤å¤„ä½ éœ€è¦ä½¿ç”¨å’Œæ„å»ºæ—¶ç›¸åŒçš„ Emeddingã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../C3 æ­å»ºçŸ¥è¯†åº“\") # å°†çˆ¶ç›®å½•æ”¾å…¥ç³»ç»Ÿè·¯å¾„ä¸­\n",
    "\n",
    "# ä½¿ç”¨æ™ºè°± Embedding APIï¼Œæ³¨æ„ï¼Œéœ€è¦å°†ä¸Šä¸€ç« å®ç°çš„å°è£…ä»£ç ä¸‹è½½åˆ°æœ¬åœ°\n",
    "from zhipuai_embedding import ZhipuAIEmbeddings\n",
    "\n",
    "from langchain.vectorstores.chroma import Chroma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ä»ç¯å¢ƒå˜é‡ä¸­åŠ è½½ä½ çš„ API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "import os\n",
    "\n",
    "_ = load_dotenv(find_dotenv())    # read local .env file\n",
    "zhipuai_api_key = os.environ['ZHIPUAI_API_KEY']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "åŠ è½½å‘é‡æ•°æ®åº“ï¼Œå…¶ä¸­åŒ…å«äº† ../../data_base/knowledge_db ä¸‹å¤šä¸ªæ–‡æ¡£çš„ Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å®šä¹‰ Embeddings\n",
    "embedding = ZhipuAIEmbeddings()\n",
    "\n",
    "# å‘é‡æ•°æ®åº“æŒä¹…åŒ–è·¯å¾„\n",
    "persist_directory = '../../data_base/vector_db/chroma'\n",
    "\n",
    "# åŠ è½½æ•°æ®åº“\n",
    "vectordb = Chroma(\n",
    "    persist_directory=persist_directory,  # å…è®¸æˆ‘ä»¬å°†persist_directoryç›®å½•ä¿å­˜åˆ°ç£ç›˜ä¸Š\n",
    "    embedding_function=embedding\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"å‘é‡åº“ä¸­å­˜å‚¨çš„æ•°é‡ï¼š{vectordb._collection.count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æˆ‘ä»¬å¯ä»¥æµ‹è¯•ä¸€ä¸‹åŠ è½½çš„å‘é‡æ•°æ®åº“ï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡`as_retriever`æ–¹æ³•æŠŠå‘é‡æ•°æ®åº“æ„é€ æˆæ£€ç´¢å™¨ã€‚æˆ‘ä»¬ä½¿ç”¨ä¸€ä¸ªé—®é¢˜ query è¿›è¡Œå‘é‡æ£€ç´¢ã€‚å¦‚ä¸‹ä»£ç ä¼šåœ¨å‘é‡æ•°æ®åº“ä¸­æ ¹æ®ç›¸ä¼¼æ€§è¿›è¡Œæ£€ç´¢ï¼Œè¿”å›å‰ k ä¸ªæœ€ç›¸ä¼¼çš„æ–‡æ¡£ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"ä»€ä¹ˆæ˜¯prompt engineering?\"\n",
    "retriever = vectordb.as_retriever(search_kwargs={\"k\": 3})\n",
    "docs = retriever.invoke(question)\n",
    "print(f\"æ£€ç´¢åˆ°çš„å†…å®¹æ•°ï¼š{len(docs)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æ‰“å°ä¸€ä¸‹æ£€ç´¢åˆ°çš„å†…å®¹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, doc in enumerate(docs):\n",
    "    print(f\"æ£€ç´¢åˆ°çš„ç¬¬{i}ä¸ªå†…å®¹: \\n {doc.page_content}\", end=\"\\n-----------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.2åˆ›å»ºæ£€ç´¢é“¾\n",
    "æˆ‘ä»¬å¯ä»¥ä½¿ç”¨LangChainçš„LCEL(LangChain Expression Language, LangChainè¡¨è¾¾å¼è¯­è¨€)æ¥æ„å»ºworkflowï¼ŒLCELå¯ä»¥æ”¯æŒå¼‚æ­¥ï¼ˆainvokeï¼‰ã€æµå¼(stream)ã€æ‰¹æ¬¡å¤„ç†(batch)ç­‰å¤šç§è¿è¡Œæ–¹å¼ï¼ŒåŒæ—¶è¿˜å¯ä»¥ä½¿ç”¨LangSmithæ— ç¼è·Ÿè¸ªã€‚\n",
    "\n",
    "æ¥ä¸‹æ¥æˆ‘ä»¬ä½¿ç”¨åˆšæ‰å®šä¹‰çš„retrieverå®šä¹‰ä¸€ä¸ªç®€å•çš„æ£€ç´¢é“¾ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "def combine_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "combiner = RunnableLambda(combine_docs)\n",
    "retrieval_chain = retriever | combiner\n",
    "\n",
    "retrieval_chain.invoke(\"å—ç“œä¹¦æ˜¯ä»€ä¹ˆï¼Ÿ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LCELä¸­è¦æ±‚æ‰€æœ‰çš„ç»„æˆå…ƒç´ éƒ½æ˜¯`Runnable`ç±»å‹ï¼Œå‰é¢æˆ‘ä»¬è§è¿‡çš„`ChatModel`ã€`PromptTemplate`ç­‰éƒ½æ˜¯ç»§æ‰¿è‡ª`Runnable`ç±»ã€‚ä¸Šæ–¹çš„`retrieval_chain`æ˜¯ç”±æ£€ç´¢å™¨`retriever`åŠç»„åˆå™¨`combiner`ç»„æˆçš„ï¼Œç”±`|`ç¬¦å·ä¸²è¿ï¼Œæ•°æ®ä»å·¦å‘å³ä¼ é€’ï¼Œå³é—®é¢˜å…ˆè¢«`retriever`æ£€ç´¢å¾—åˆ°æ£€ç´¢ç»“æœï¼Œå†è¢«`combiner`è¿›ä¸€æ­¥å¤„ç†å¹¶è¾“å‡ºã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.3 åˆ›å»ºLLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬è°ƒç”¨ OpenAI çš„ API åˆ›å»ºä¸€ä¸ª LLMï¼Œå½“ç„¶ä½ ä¹Ÿå¯ä»¥ä½¿ç”¨å…¶ä»– LLM çš„ API è¿›è¡Œåˆ›å»º"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "OPENAI_API_KEY = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(model_name=\"gpt-4o\", temperature=0)\n",
    "\n",
    "llm.invoke(\"è¯·ä½ è‡ªæˆ‘ä»‹ç»ä¸€ä¸‹è‡ªå·±ï¼\").content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.4 æ„å»ºæ£€ç´¢é—®ç­”é“¾"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableParallel\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "template = \"\"\"ä½¿ç”¨ä»¥ä¸‹ä¸Šä¸‹æ–‡æ¥å›ç­”æœ€åçš„é—®é¢˜ã€‚å¦‚æœä½ ä¸çŸ¥é“ç­”æ¡ˆï¼Œå°±è¯´ä½ ä¸çŸ¥é“ï¼Œä¸è¦è¯•å›¾ç¼–é€ ç­”\n",
    "æ¡ˆã€‚æœ€å¤šä½¿ç”¨ä¸‰å¥è¯ã€‚å°½é‡ä½¿ç­”æ¡ˆç®€æ˜æ‰¼è¦ã€‚è¯·ä½ åœ¨å›ç­”çš„æœ€åè¯´â€œè°¢è°¢ä½ çš„æé—®ï¼â€ã€‚\n",
    "{context}\n",
    "é—®é¢˜: {input}\n",
    "\"\"\"\n",
    "# å°†templateé€šè¿‡ PromptTemplate è½¬ä¸ºå¯ä»¥åœ¨LCELä¸­ä½¿ç”¨çš„ç±»å‹\n",
    "prompt = PromptTemplate(template=template)\n",
    "\n",
    "qa_chain = (\n",
    "    RunnableParallel({\"context\": retrieval_chain, \"input\": RunnablePassthrough()})\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "åœ¨ä¸Šè¾¹ä»£ç ä¸­æˆ‘ä»¬æŠŠåˆšæ‰å®šä¹‰çš„æ£€ç´¢é“¾å½“ä½œå­é“¾ä½œä¸º`prompt`çš„`context`ï¼Œå†ä½¿ç”¨`RunnablePassthrough`å­˜å‚¨ç”¨æˆ·çš„é—®é¢˜ä½œä¸º`prompt`çš„`input`ã€‚åˆå› ä¸ºè¿™ä¸¤ä¸ªæ“ä½œæ˜¯å¹¶è¡Œçš„ï¼Œæ‰€ä»¥æˆ‘ä»¬ä½¿ç”¨`RunnableParallel`æ¥å°†ä»–ä»¬å¹¶è¡Œè¿è¡Œã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**æ£€ç´¢é—®ç­”é“¾æ•ˆæœæµ‹è¯•**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_1 = \"ä»€ä¹ˆæ˜¯å—ç“œä¹¦ï¼Ÿ\"\n",
    "question_2 = \"Prompt Engineering for Developeræ˜¯è°å†™çš„ï¼Ÿ\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = qa_chain.invoke(question_1)\n",
    "print(\"å¤§æ¨¡å‹+çŸ¥è¯†åº“åå›ç­” question_1 çš„ç»“æœï¼š\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = qa_chain.invoke(question_2)\n",
    "print(\"å¤§æ¨¡å‹+çŸ¥è¯†åº“åå›ç­” question_2 çš„ç»“æœï¼š\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**å¤§æ¨¡å‹è‡ªå·±å›ç­”çš„æ•ˆæœ**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm.invoke(question_1).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm.invoke(question_2).content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> â­ é€šè¿‡ä»¥ä¸Šä¸¤ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬å‘ç° LLM å¯¹äºä¸€äº›è¿‘å‡ å¹´çš„çŸ¥è¯†ä»¥åŠéå¸¸è¯†æ€§çš„ä¸“ä¸šé—®é¢˜ï¼Œå›ç­”çš„å¹¶ä¸æ˜¯å¾ˆå¥½ã€‚è€ŒåŠ ä¸Šæˆ‘ä»¬çš„æœ¬åœ°çŸ¥è¯†ï¼Œå°±å¯ä»¥å¸®åŠ© LLM åšå‡ºæ›´å¥½çš„å›ç­”ã€‚å¦å¤–ï¼Œä¹Ÿæœ‰åŠ©äºç¼“è§£å¤§æ¨¡å‹çš„â€œå¹»è§‰â€é—®é¢˜ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.5 å‘æ£€ç´¢é“¾æ·»åŠ èŠå¤©è®°å½•"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ç°åœ¨æˆ‘ä»¬å·²ç»å®ç°äº†é€šè¿‡ä¸Šä¼ æœ¬åœ°çŸ¥è¯†æ–‡æ¡£ï¼Œç„¶åå°†ä»–ä»¬ä¿å­˜åˆ°å‘é‡çŸ¥è¯†åº“ï¼Œé€šè¿‡å°†æŸ¥è¯¢é—®é¢˜ä¸å‘é‡çŸ¥è¯†åº“çš„å¬å›ç»“æœè¿›è¡Œç»“åˆè¾“å…¥åˆ° LLM ä¸­ï¼Œæˆ‘ä»¬å°±å¾—åˆ°äº†ä¸€ä¸ªç›¸æ¯”äºç›´æ¥è®© LLM å›ç­”è¦å¥½å¾—å¤šçš„ç»“æœã€‚åœ¨ä¸è¯­è¨€æ¨¡å‹äº¤äº’æ—¶ï¼Œä½ å¯èƒ½å·²ç»æ³¨æ„åˆ°ä¸€ä¸ªå…³é”®é—®é¢˜ - **å®ƒä»¬å¹¶ä¸è®°å¾—ä½ ä¹‹å‰çš„äº¤æµå†…å®¹**ã€‚è¿™åœ¨æˆ‘ä»¬æ„å»ºä¸€äº›åº”ç”¨ç¨‹åºï¼ˆå¦‚èŠå¤©æœºå™¨äººï¼‰çš„æ—¶å€™ï¼Œå¸¦æ¥äº†å¾ˆå¤§çš„æŒ‘æˆ˜ï¼Œä½¿å¾—å¯¹è¯ä¼¼ä¹ç¼ºä¹çœŸæ­£çš„è¿ç»­æ€§ã€‚è¿™ä¸ªé—®é¢˜è¯¥å¦‚ä½•è§£å†³å‘¢ï¼Ÿ\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ä¼ é€’èŠå¤©è®°å½•**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "åœ¨æœ¬èŠ‚ä¸­æˆ‘ä»¬å°†ä½¿ç”¨ LangChain ä¸­çš„`ChatPromptTemplate`ï¼Œå³å°†å…ˆå‰çš„å¯¹è¯åµŒå…¥åˆ°è¯­è¨€æ¨¡å‹ä¸­ï¼Œä½¿å…¶å…·æœ‰è¿ç»­å¯¹è¯çš„èƒ½åŠ›ã€‚ `ChatPromptTemplate`å¯ä»¥æ¥æ”¶èŠå¤©æ¶ˆæ¯å†å²è®°å½•ï¼Œè¿™äº›å†å²è®°å½•å°†åœ¨å›ç­”é—®é¢˜æ—¶ä¸é—®é¢˜ä¸€èµ·ä¼ é€’ç»™èŠå¤©æœºå™¨äººï¼Œä»è€Œå°†å®ƒä»¬æ·»åŠ åˆ°ä¸Šä¸‹æ–‡ä¸­ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# é—®ç­”é“¾çš„ç³»ç»Ÿprompt\n",
    "system_prompt = (\n",
    "    \"ä½ æ˜¯ä¸€ä¸ªé—®ç­”ä»»åŠ¡çš„åŠ©æ‰‹ã€‚ \"\n",
    "    \"è¯·ä½¿ç”¨æ£€ç´¢åˆ°çš„ä¸Šä¸‹æ–‡ç‰‡æ®µå›ç­”è¿™ä¸ªé—®é¢˜ã€‚ \"\n",
    "    \"å¦‚æœä½ ä¸çŸ¥é“ç­”æ¡ˆå°±è¯´ä¸çŸ¥é“ã€‚ \"\n",
    "    \"è¯·ä½¿ç”¨ç®€æ´çš„è¯è¯­å›ç­”ç”¨æˆ·ã€‚\"\n",
    "    \"\\n\\n\"\n",
    "    \"{context}\"\n",
    ")\n",
    "# åˆ¶å®šprompt template\n",
    "qa_prompt = ChatPromptTemplate(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        (\"placeholder\", \"{chat_history}\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ— å†å²è®°å½•\n",
    "messages = qa_prompt.invoke(\n",
    "    {\n",
    "        \"input\": \"å—ç“œä¹¦æ˜¯ä»€ä¹ˆï¼Ÿ\",\n",
    "        \"chat_history\": [],\n",
    "        \"context\": \"\"\n",
    "    }\n",
    ")\n",
    "for message in messages.messages:\n",
    "    print(message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æœ‰å†å²è®°å½•\n",
    "messages = qa_prompt.invoke(\n",
    "    {\n",
    "        \"input\": \"ä½ å¯ä»¥ä»‹ç»ä¸€ä¸‹ä»–å—ï¼Ÿ\",\n",
    "        \"chat_history\": [\n",
    "            (\"human\", \"è¥¿ç“œä¹¦æ˜¯ä»€ä¹ˆï¼Ÿ\"),\n",
    "            (\"ai\", \"è¥¿ç“œä¹¦æ˜¯æŒ‡å‘¨å¿—åè€å¸ˆçš„ã€Šæœºå™¨å­¦ä¹ ã€‹ä¸€ä¹¦ï¼Œæ˜¯æœºå™¨å­¦ä¹ é¢†åŸŸçš„ç»å…¸å…¥é—¨æ•™æä¹‹ä¸€ã€‚\"),\n",
    "        ],\n",
    "        \"context\": \"\"\n",
    "    }\n",
    ")\n",
    "for message in messages.messages:\n",
    "    print(message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.6 å¸¦æœ‰ä¿¡æ¯å‹ç¼©çš„æ£€ç´¢é“¾"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "å› ä¸ºæˆ‘ä»¬æ­£åœ¨æ­å»ºçš„é—®ç­”é“¾å¸¦æœ‰æ”¯æŒå¤šè½®å¯¹è¯åŠŸèƒ½ï¼Œæ‰€ä»¥ä¸å•è½®å¯¹è¯çš„é—®ç­”é“¾ç›¸æ¯”ä¼šå¤šé¢ä¸´åƒä¸Šæ–¹è¾“å‡ºç»“æœçš„é—®é¢˜ï¼Œå³ç”¨æˆ·æœ€æ–°çš„å¯¹è¯è¯­ä¹‰ä¸å…¨ï¼Œåœ¨ä½¿ç”¨ç”¨æˆ·é—®é¢˜æŸ¥è¯¢å‘é‡æ•°æ®åº“æ—¶å¾ˆéš¾æ£€ç´¢åˆ°ç›¸å…³ä¿¡æ¯ã€‚åƒä¸Šæ–¹çš„â€œä½ å¯ä»¥ä»‹ç»ä¸€ä¸‹ä»–å—ï¼Ÿâ€ï¼Œå…¶å®æ˜¯â€œä½ å¯ä»¥ä»‹ç»ä¸‹å‘¨å¿—åè€å¸ˆå—ï¼Ÿâ€çš„æ„æ€ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜æˆ‘ä»¬å°†é‡‡å–ä¿¡æ¯å‹ç¼©çš„æ–¹å¼ï¼Œè®©llmæ ¹æ®å†å²è®°å½•å®Œå–„ç”¨æˆ·çš„é—®é¢˜ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableBranch\n",
    "\n",
    "# å‹ç¼©é—®é¢˜çš„ç³»ç»Ÿ prompt\n",
    "condense_question_system_template = (\n",
    "    \"è¯·æ ¹æ®èŠå¤©è®°å½•å®Œå–„ç”¨æˆ·æœ€æ–°çš„é—®é¢˜ï¼Œ\"\n",
    "    \"å¦‚æœç”¨æˆ·æœ€æ–°çš„é—®é¢˜ä¸éœ€è¦å®Œå–„åˆ™è¿”å›ç”¨æˆ·çš„é—®é¢˜ã€‚\"\n",
    "    )\n",
    "# æ„é€  å‹ç¼©é—®é¢˜çš„ prompt template\n",
    "condense_question_prompt = ChatPromptTemplate([\n",
    "        (\"system\", condense_question_system_template),\n",
    "        (\"placeholder\", \"{chat_history}\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ])\n",
    "# æ„é€ æ£€ç´¢æ–‡æ¡£çš„é“¾\n",
    "# RunnableBranch ä¼šæ ¹æ®æ¡ä»¶é€‰æ‹©è¦è¿è¡Œçš„åˆ†æ”¯\n",
    "retrieve_docs = RunnableBranch(\n",
    "    # åˆ†æ”¯ 1: è‹¥èŠå¤©è®°å½•ä¸­æ²¡æœ‰ chat_history åˆ™ç›´æ¥ä½¿ç”¨ç”¨æˆ·é—®é¢˜æŸ¥è¯¢å‘é‡æ•°æ®åº“\n",
    "    (lambda x: not x.get(\"chat_history\", False), (lambda x: x[\"input\"]) | retriever, ),\n",
    "    # åˆ†æ”¯ 2 : è‹¥èŠå¤©è®°å½•ä¸­æœ‰ chat_history åˆ™å…ˆè®© llm æ ¹æ®èŠå¤©è®°å½•å®Œå–„é—®é¢˜å†æŸ¥è¯¢å‘é‡æ•°æ®åº“\n",
    "    condense_question_prompt | llm | StrOutputParser() | retriever,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**æ”¯æŒèŠå¤©è®°å½•çš„æ£€ç´¢é—®ç­”é“¾**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "è¿™é‡Œæˆ‘ä»¬ä½¿ç”¨ä¹‹å‰å®šä¹‰çš„é—®ç­”æ¨¡æ¿å³`qa_prompt`æ„é€ é—®ç­”é“¾ï¼Œå¦å¤–æˆ‘ä»¬é€šè¿‡`RunnablePassthrough.assign`å°†ä¸­é—´çš„æŸ¥è¯¢ç»“æœå­˜ä¸º`\"context\"`ï¼Œå°†æœ€ç»ˆç»“æœå­˜ä¸º`\"answer\"`ã€‚å› ä¸ºæŸ¥è¯¢ç»“æœè¢«å­˜ä¸º`\"context\"`ï¼Œæ‰€ä»¥æˆ‘ä»¬æ•´åˆæŸ¥è¯¢ç»“æœçš„å‡½æ•°`combine_docs`ä¹Ÿè¦åšç›¸åº”çš„æ”¹åŠ¨ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# é‡æ–°å®šä¹‰ combine_docs\n",
    "def combine_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs[\"context\"]) # å°† docs æ”¹ä¸º docs[\"context\"]\n",
    "# å®šä¹‰é—®ç­”é“¾\n",
    "qa_chain = (\n",
    "    RunnablePassthrough.assign(context=combine_docs) # ä½¿ç”¨ combine_docs å‡½æ•°æ•´åˆ qa_prompt ä¸­çš„ context\n",
    "    | qa_prompt # é—®ç­”æ¨¡æ¿\n",
    "    | llm\n",
    "    | StrOutputParser() # è§„å®šè¾“å‡ºçš„æ ¼å¼ä¸º str\n",
    ")\n",
    "# å®šä¹‰å¸¦æœ‰å†å²è®°å½•çš„é—®ç­”é“¾\n",
    "qa_history_chain = RunnablePassthrough.assign(\n",
    "    context = (lambda x: x) | retrieve_docs # å°†æŸ¥è¯¢ç»“æœå­˜ä¸º content\n",
    "    ).assign(answer=qa_chain) # å°†æœ€ç»ˆç»“æœå­˜ä¸º answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**æµ‹è¯•æ£€ç´¢é—®ç­”é“¾**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ä¸å¸¦èŠå¤©è®°å½•\n",
    "qa_history_chain.invoke({\n",
    "    \"input\": \"è¥¿ç“œä¹¦æ˜¯ä»€ä¹ˆï¼Ÿ\",\n",
    "    \"chat_history\": []\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¸¦èŠå¤©è®°å½•\n",
    "qa_history_chain.invoke({\n",
    "    \"input\": \"å—ç“œä¹¦è·Ÿå®ƒæœ‰ä»€ä¹ˆå…³ç³»ï¼Ÿ\",\n",
    "    \"chat_history\": [\n",
    "        (\"human\", \"è¥¿ç“œä¹¦æ˜¯ä»€ä¹ˆï¼Ÿ\"),\n",
    "        (\"ai\", \"è¥¿ç“œä¹¦æ˜¯æŒ‡å‘¨å¿—åè€å¸ˆçš„ã€Šæœºå™¨å­¦ä¹ ã€‹ä¸€ä¹¦ï¼Œæ˜¯æœºå™¨å­¦ä¹ é¢†åŸŸçš„ç»å…¸å…¥é—¨æ•™æä¹‹ä¸€ã€‚\"),\n",
    "    ]\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "å¯ä»¥çœ‹åˆ°ï¼ŒLLM å‡†ç¡®åœ°åˆ¤æ–­äº†â€œå®ƒâ€æ˜¯ä»€ä¹ˆï¼Œä»£è¡¨ç€æˆ‘ä»¬æˆåŠŸåœ°ä¼ é€’ç»™äº†å®ƒå†å²ä¿¡æ¯ã€‚å¦å¤–å¬å›çš„å†…å®¹ä¹Ÿæœ‰ç€é—®é¢˜çš„ç­”æ¡ˆï¼Œè¯æ˜æˆ‘ä»¬çš„ä¿¡æ¯å‹ç¼©ç­–ç•¥ä¹Ÿèµ·åˆ°äº†ä½œç”¨ã€‚è¿™ç§å…³è”å‰åé—®é¢˜åŠå‹ç¼©ä¿¡æ¯å¹¶æ£€ç´¢çš„èƒ½åŠ›ï¼Œå¯å¤§å¤§å¢å¼ºé—®ç­”ç³»ç»Ÿçš„è¿ç»­æ€§å’Œæ™ºèƒ½æ°´å¹³ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 éƒ¨ç½²çŸ¥è¯†åº“åŠ©æ‰‹\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æˆ‘ä»¬å¯¹çŸ¥è¯†åº“å’ŒLLMå·²ç»æœ‰äº†åŸºæœ¬çš„ç†è§£ï¼Œç°åœ¨æ˜¯å°†å®ƒä»¬å·§å¦™åœ°èåˆå¹¶æ‰“é€ æˆä¸€ä¸ªå¯Œæœ‰è§†è§‰æ•ˆæœçš„ç•Œé¢çš„æ—¶å€™äº†ã€‚è¿™æ ·çš„ç•Œé¢ä¸ä»…å¯¹æ“ä½œæ›´åŠ ä¾¿æ·ï¼Œè¿˜èƒ½ä¾¿äºä¸ä»–äººåˆ†äº«ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Streamlit æ˜¯ä¸€ç§å¿«é€Ÿä¾¿æ·çš„æ–¹æ³•ï¼Œå¯ä»¥ç›´æ¥åœ¨ **Python ä¸­é€šè¿‡å‹å¥½çš„ Web ç•Œé¢æ¼”ç¤ºæœºå™¨å­¦ä¹ æ¨¡å‹**ã€‚åœ¨æœ¬è¯¾ç¨‹ä¸­ï¼Œæˆ‘ä»¬å°†å­¦ä¹ *å¦‚ä½•ä½¿ç”¨å®ƒä¸ºç”Ÿæˆå¼äººå·¥æ™ºèƒ½åº”ç”¨ç¨‹åºæ„å»ºç”¨æˆ·ç•Œé¢*ã€‚åœ¨æ„å»ºäº†æœºå™¨å­¦ä¹ æ¨¡å‹åï¼Œå¦‚æœä½ æƒ³æ„å»ºä¸€ä¸ª demo ç»™å…¶ä»–äººçœ‹ï¼Œä¹Ÿè®¸æ˜¯ä¸ºäº†è·å¾—åé¦ˆå¹¶æ¨åŠ¨ç³»ç»Ÿçš„æ”¹è¿›ï¼Œæˆ–è€…åªæ˜¯å› ä¸ºä½ è§‰å¾—è¿™ä¸ªç³»ç»Ÿå¾ˆé…·ï¼Œæ‰€ä»¥æƒ³æ¼”ç¤ºä¸€ä¸‹ï¼šStreamlit å¯ä»¥è®©æ‚¨é€šè¿‡ Python æ¥å£ç¨‹åºå¿«é€Ÿå®ç°è¿™ä¸€ç›®æ ‡ï¼Œè€Œæ— éœ€ç¼–å†™ä»»ä½•å‰ç«¯ã€ç½‘é¡µæˆ– JavaScript ä»£ç ã€‚\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.1 Streamlit ç®€ä»‹"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "`Streamlit` æ˜¯ä¸€ä¸ªç”¨äºå¿«é€Ÿåˆ›å»ºæ•°æ®åº”ç”¨ç¨‹åºçš„å¼€æº Python åº“ã€‚å®ƒçš„è®¾è®¡ç›®æ ‡æ˜¯è®©æ•°æ®ç§‘å­¦å®¶èƒ½å¤Ÿè½»æ¾åœ°å°†æ•°æ®åˆ†æå’Œæœºå™¨å­¦ä¹ æ¨¡å‹è½¬åŒ–ä¸ºå…·æœ‰äº¤äº’æ€§çš„ Web åº”ç”¨ç¨‹åºï¼Œè€Œæ— éœ€æ·±å…¥äº†è§£ Web å¼€å‘ã€‚å’Œå¸¸è§„ Web æ¡†æ¶ï¼Œå¦‚ Flask/Django çš„ä¸åŒä¹‹å¤„åœ¨äºï¼Œå®ƒä¸éœ€è¦ä½ å»ç¼–å†™ä»»ä½•å®¢æˆ·ç«¯ä»£ç ï¼ˆHTML/CSS/JSï¼‰ï¼Œåªéœ€è¦ç¼–å†™æ™®é€šçš„ Python æ¨¡å—ï¼Œå°±å¯ä»¥åœ¨å¾ˆçŸ­çš„æ—¶é—´å†…åˆ›å»ºç¾è§‚å¹¶å…·å¤‡é«˜åº¦äº¤äº’æ€§çš„ç•Œé¢ï¼Œä»è€Œå¿«é€Ÿç”Ÿæˆæ•°æ®åˆ†ææˆ–è€…æœºå™¨å­¦ä¹ çš„ç»“æœï¼›å¦ä¸€æ–¹é¢ï¼Œå’Œé‚£äº›åªèƒ½é€šè¿‡æ‹–æ‹½ç”Ÿæˆçš„å·¥å…·ä¹Ÿä¸åŒçš„æ˜¯ï¼Œä½ ä»ç„¶å…·æœ‰å¯¹ä»£ç çš„å®Œæ•´æ§åˆ¶æƒã€‚\n",
    "\n",
    "Streamlit æä¾›äº†ä¸€ç»„ç®€å•è€Œå¼ºå¤§çš„åŸºç¡€æ¨¡å—ï¼Œç”¨äºæ„å»ºæ•°æ®åº”ç”¨ç¨‹åºï¼š\n",
    "\n",
    "- st.write()ï¼šè¿™æ˜¯æœ€åŸºæœ¬çš„æ¨¡å—ä¹‹ä¸€ï¼Œç”¨äºåœ¨åº”ç”¨ç¨‹åºä¸­å‘ˆç°æ–‡æœ¬ã€å›¾åƒã€è¡¨æ ¼ç­‰å†…å®¹ã€‚\n",
    "\n",
    "- st.title()ã€st.header()ã€st.subheader()ï¼šè¿™äº›æ¨¡å—ç”¨äºæ·»åŠ æ ‡é¢˜ã€å­æ ‡é¢˜å’Œåˆ†ç»„æ ‡é¢˜ï¼Œä»¥ç»„ç»‡åº”ç”¨ç¨‹åºçš„å¸ƒå±€ã€‚\n",
    "\n",
    "- st.text()ã€st.markdown()ï¼šç”¨äºæ·»åŠ æ–‡æœ¬å†…å®¹ï¼Œæ”¯æŒ Markdown è¯­æ³•ã€‚\n",
    "\n",
    "- st.image()ï¼šç”¨äºæ·»åŠ å›¾åƒåˆ°åº”ç”¨ç¨‹åºä¸­ã€‚\n",
    "\n",
    "- st.dataframe()ï¼šç”¨äºå‘ˆç° Pandas æ•°æ®æ¡†ã€‚\n",
    "\n",
    "- st.table()ï¼šç”¨äºå‘ˆç°ç®€å•çš„æ•°æ®è¡¨æ ¼ã€‚\n",
    "\n",
    "- st.pyplot()ã€st.altair_chart()ã€st.plotly_chart()ï¼šç”¨äºå‘ˆç° Matplotlibã€Altair æˆ– Plotly ç»˜åˆ¶çš„å›¾è¡¨ã€‚\n",
    "\n",
    "- st.selectbox()ã€st.multiselect()ã€st.slider()ã€st.text_input()ï¼šç”¨äºæ·»åŠ äº¤äº’å¼å°éƒ¨ä»¶ï¼Œå…è®¸ç”¨æˆ·åœ¨åº”ç”¨ç¨‹åºä¸­è¿›è¡Œé€‰æ‹©ã€è¾“å…¥æˆ–æ»‘åŠ¨æ“ä½œã€‚\n",
    "\n",
    "- st.button()ã€st.checkbox()ã€st.radio()ï¼šç”¨äºæ·»åŠ æŒ‰é’®ã€å¤é€‰æ¡†å’Œå•é€‰æŒ‰é’®ï¼Œä»¥è§¦å‘ç‰¹å®šçš„æ“ä½œã€‚\n",
    "\n",
    "è¿™äº›åŸºç¡€æ¨¡å—ä½¿å¾—é€šè¿‡ Streamlit èƒ½å¤Ÿè½»æ¾åœ°æ„å»ºäº¤äº’å¼æ•°æ®åº”ç”¨ç¨‹åºï¼Œå¹¶ä¸”åœ¨ä½¿ç”¨æ—¶å¯ä»¥æ ¹æ®éœ€è¦è¿›è¡Œç»„åˆå’Œå®šåˆ¶ï¼Œæ›´å¤šå†…å®¹è¯·æŸ¥çœ‹[å®˜æ–¹æ–‡æ¡£](https://docs.streamlit.io/get-started)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.2 æ„å»ºåº”ç”¨ç¨‹åº"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "é¦–å…ˆï¼Œåˆ›å»ºä¸€ä¸ªæ–°çš„ Python æ–‡ä»¶å¹¶å°†å…¶ä¿å­˜ streamlit_app.pyåœ¨å·¥ä½œç›®å½•çš„æ ¹ç›®å½•ä¸­"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. å¯¼å…¥å¿…è¦çš„ Python åº“ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableBranch, RunnablePassthrough\n",
    "import sys\n",
    "sys.path.append(\"notebook/C3 æ­å»ºçŸ¥è¯†åº“\") # å°†çˆ¶ç›®å½•æ”¾å…¥ç³»ç»Ÿè·¯å¾„ä¸­\n",
    "from zhipuai_embedding import ZhipuAIEmbeddings\n",
    "from langchain_community.vectorstores import Chroma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. å®šä¹‰`get_retriever`å‡½æ•°ï¼Œè¯¥å‡½æ•°è¿”å›ä¸€ä¸ªæ£€ç´¢å™¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_retriever():\n",
    "    # å®šä¹‰ Embeddings\n",
    "    embedding = ZhipuAIEmbeddings()\n",
    "    # å‘é‡æ•°æ®åº“æŒä¹…åŒ–è·¯å¾„\n",
    "    persist_directory = 'data_base/vector_db/chroma'\n",
    "    # åŠ è½½æ•°æ®åº“\n",
    "    vectordb = Chroma(\n",
    "        persist_directory=persist_directory,\n",
    "        embedding_function=embedding\n",
    "    )\n",
    "    return vectordb.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. å®šä¹‰`combine_docs`å‡½æ•°ï¼Œ è¯¥å‡½æ•°å¤„ç†æ£€ç´¢å™¨è¿”å›çš„æ–‡æœ¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs[\"context\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. å®šä¹‰`get_qa_history_chain`å‡½æ•°ï¼Œè¯¥å‡½æ•°å¯ä»¥è¿”å›ä¸€ä¸ªæ£€ç´¢é—®ç­”é“¾"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_qa_history_chain():\n",
    "    retriever = get_retriever()\n",
    "    llm = ChatOpenAI(model_name=\"gpt-4o\", temperature=0)\n",
    "    condense_question_system_template = (\n",
    "        \"è¯·æ ¹æ®èŠå¤©è®°å½•æ€»ç»“ç”¨æˆ·æœ€è¿‘çš„é—®é¢˜ï¼Œ\"\n",
    "        \"å¦‚æœæ²¡æœ‰å¤šä½™çš„èŠå¤©è®°å½•åˆ™è¿”å›ç”¨æˆ·çš„é—®é¢˜ã€‚\"\n",
    "    )\n",
    "    condense_question_prompt = ChatPromptTemplate([\n",
    "            (\"system\", condense_question_system_template),\n",
    "            (\"placeholder\", \"{chat_history}\"),\n",
    "            (\"human\", \"{input}\"),\n",
    "        ])\n",
    "\n",
    "    retrieve_docs = RunnableBranch(\n",
    "        (lambda x: not x.get(\"chat_history\", False), (lambda x: x[\"input\"]) | retriever, ),\n",
    "        condense_question_prompt | llm | StrOutputParser() | retriever,\n",
    "    )\n",
    "\n",
    "    system_prompt = (\n",
    "        \"ä½ æ˜¯ä¸€ä¸ªé—®ç­”ä»»åŠ¡çš„åŠ©æ‰‹ã€‚ \"\n",
    "        \"è¯·ä½¿ç”¨æ£€ç´¢åˆ°çš„ä¸Šä¸‹æ–‡ç‰‡æ®µå›ç­”è¿™ä¸ªé—®é¢˜ã€‚ \"\n",
    "        \"å¦‚æœä½ ä¸çŸ¥é“ç­”æ¡ˆå°±è¯´ä¸çŸ¥é“ã€‚ \"\n",
    "        \"è¯·ä½¿ç”¨ç®€æ´çš„è¯è¯­å›ç­”ç”¨æˆ·ã€‚\"\n",
    "        \"\\n\\n\"\n",
    "        \"{context}\"\n",
    "    )\n",
    "    qa_prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", system_prompt),\n",
    "            (\"placeholder\", \"{chat_history}\"),\n",
    "            (\"human\", \"{input}\"),\n",
    "        ]\n",
    "    )\n",
    "    qa_chain = (\n",
    "        RunnablePassthrough().assign(context=combine_docs)\n",
    "        | qa_prompt\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "\n",
    "    qa_history_chain = RunnablePassthrough().assign(\n",
    "        context = retrieve_docs, \n",
    "        ).assign(answer=qa_chain)\n",
    "    return qa_history_chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. å®šä¹‰`gen_response`å‡½æ•°ï¼Œå®ƒæ¥å—æ£€ç´¢é—®ç­”é“¾ã€ç”¨æˆ·è¾“å…¥åŠèŠå¤©å†å²ï¼Œå¹¶ä»¥æµå¼è¿”å›è¯¥é“¾è¾“å‡º"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_response(chain, input, chat_history):\n",
    "    response = chain.stream({\n",
    "        \"input\": input,\n",
    "        \"chat_history\": chat_history\n",
    "    })\n",
    "    for res in response:\n",
    "        if \"answer\" in res.keys():\n",
    "            yield res[\"answer\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. å®šä¹‰mainå‡½æ•°ï¼Œè¯¥å‡½æ•°åˆ¶å®šæ˜¾ç¤ºæ•ˆæœä¸é€»è¾‘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    st.markdown('### ğŸ¦œğŸ”— åŠ¨æ‰‹å­¦å¤§æ¨¡å‹åº”ç”¨å¼€å‘')\n",
    "    # st.session_stateå¯ä»¥å­˜å‚¨ç”¨æˆ·ä¸åº”ç”¨äº¤äº’æœŸé—´çš„çŠ¶æ€ä¸æ•°æ®\n",
    "    # å­˜å‚¨å¯¹è¯å†å²\n",
    "    if \"messages\" not in st.session_state:\n",
    "        st.session_state.messages = []\n",
    "    # å­˜å‚¨æ£€ç´¢é—®ç­”é“¾\n",
    "    if \"qa_history_chain\" not in st.session_state:\n",
    "        st.session_state.qa_history_chain = get_qa_history_chain()\n",
    "    # å»ºç«‹å®¹å™¨ é«˜åº¦ä¸º500 px\n",
    "    messages = st.container(height=550)\n",
    "    # æ˜¾ç¤ºæ•´ä¸ªå¯¹è¯å†å²\n",
    "    for message in st.session_state.messages: # éå†å¯¹è¯å†å²\n",
    "            with messages.chat_message(message[0]): # messagesæŒ‡åœ¨å®¹å™¨ä¸‹æ˜¾ç¤ºï¼Œchat_messageæ˜¾ç¤ºç”¨æˆ·åŠaiå¤´åƒ\n",
    "                st.write(message[1]) # æ‰“å°å†…å®¹\n",
    "    if prompt := st.chat_input(\"Say something\"):\n",
    "        # å°†ç”¨æˆ·è¾“å…¥æ·»åŠ åˆ°å¯¹è¯å†å²ä¸­\n",
    "        st.session_state.messages.append((\"human\", prompt))\n",
    "        # æ˜¾ç¤ºå½“å‰ç”¨æˆ·è¾“å…¥\n",
    "        with messages.chat_message(\"human\"):\n",
    "            st.write(prompt)\n",
    "        # ç”Ÿæˆå›å¤\n",
    "        answer = gen_response(\n",
    "            chain=st.session_state.qa_history_chain,\n",
    "            input=prompt,\n",
    "            chat_history=st.session_state.messages\n",
    "        )\n",
    "        # æµå¼è¾“å‡º\n",
    "        with messages.chat_message(\"ai\"):\n",
    "            output = st.write_stream(answer)\n",
    "        # å°†è¾“å‡ºå­˜å…¥st.session_state.messages\n",
    "        st.session_state.messages.append((\"ai\", output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.3 éƒ¨ç½²åº”ç”¨ç¨‹åº  \n",
    "\n",
    "**æœ¬åœ°è¿è¡Œï¼š** `streamlit run \"notebook/C4 æ„å»º RAG åº”ç”¨/streamlit_app.py\"`\n",
    "**è¿œç¨‹éƒ¨ç½²ï¼š**è¦å°†åº”ç”¨ç¨‹åºéƒ¨ç½²åˆ° Streamlit Cloudï¼Œè¯·æ‰§è¡Œä»¥ä¸‹æ­¥éª¤ï¼š  \n",
    "  \n",
    "1. ä¸ºåº”ç”¨ç¨‹åºåˆ›å»º GitHub å­˜å‚¨åº“ã€‚æ‚¨çš„å­˜å‚¨åº“åº”åŒ…å«ä¸¤ä¸ªæ–‡ä»¶ï¼š  \n",
    "  \n",
    "   your-repository/  \n",
    "   â”œâ”€â”€ streamlit_app.py  \n",
    "   â””â”€â”€ requirements.txt  \n",
    "  \n",
    "2. è½¬åˆ° [Streamlit Community Cloud](http://share.streamlit.io/)ï¼Œå•å‡»å·¥ä½œåŒºä¸­çš„`New app`æŒ‰é’®ï¼Œç„¶åæŒ‡å®šå­˜å‚¨åº“ã€åˆ†æ”¯å’Œä¸»æ–‡ä»¶è·¯å¾„ã€‚æˆ–è€…ï¼Œæ‚¨å¯ä»¥é€šè¿‡é€‰æ‹©è‡ªå®šä¹‰å­åŸŸæ¥è‡ªå®šä¹‰åº”ç”¨ç¨‹åºçš„ URL\n",
    "  \n",
    "3. ç‚¹å‡»`Deploy!`æŒ‰é’®  \n",
    "  \n",
    "æ‚¨çš„åº”ç”¨ç¨‹åºç°åœ¨å°†éƒ¨ç½²åˆ° Streamlit Community Cloudï¼Œå¹¶ä¸”å¯ä»¥ä»ä¸–ç•Œå„åœ°è®¿é—®ï¼ ğŸŒ  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æˆ‘ä»¬çš„é¡¹ç›®éƒ¨ç½²åˆ°è¿™åŸºæœ¬å®Œæˆï¼Œä¸ºäº†æ–¹ä¾¿è¿›è¡Œæ¼”ç¤ºè¿›è¡Œäº†ç®€åŒ–ï¼Œè¿˜æœ‰å¾ˆå¤šå¯ä»¥è¿›ä¸€æ­¥ä¼˜åŒ–çš„åœ°æ–¹ï¼ŒæœŸå¾…å­¦ä¹ è€…ä»¬è¿›è¡Œå„ç§é­”æ”¹ï¼\n",
    "\n",
    "ä¼˜åŒ–æ–¹å‘ï¼š\n",
    "- ç•Œé¢ä¸­æ·»åŠ ä¸Šä¼ æœ¬åœ°æ–‡æ¡£ï¼Œå»ºç«‹å‘é‡æ•°æ®åº“çš„åŠŸèƒ½\n",
    "- æ·»åŠ å¤šç§LLM ä¸ embeddingæ–¹æ³•é€‰æ‹©çš„æŒ‰é’®\n",
    "- æ·»åŠ ä¿®æ”¹å‚æ•°çš„æŒ‰é’®\n",
    "- æ›´å¤š......"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "universe_0_3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
